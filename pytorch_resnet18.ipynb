{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741054-55b8-4d99-9976-6032dbb90087",
   "metadata": {},
   "source": [
    "In this lab, we will use pre-trained models to classify between the negative and positive samples. The particular pre-trained model will be resnet18. ResNet18 is a 72-layer architecture with 18 deep layers. The architecture of this network aimed at enabling large amounts of convolutional layers to function efficiently.\n",
    "We will have three parts: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c08cf-34b0-406d-8125-0593277f34bc",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "    \n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d15041",
   "metadata": {},
   "source": [
    "dataset link: \n",
    "    https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "    https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d559de",
   "metadata": {},
   "source": [
    "After downloaded the datasets, import and use **zipfile** to extract data to customed folder for later use. detail of zipfile usage can be founded in https://github.com/HungPham14/python_code/blob/main/python_note.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b2e1a-fa06-4daf-a922-4a70777f6709",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b4424b07f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62927ada-7de8-485c-a08e-cb2b038b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/PYTHON_CODE/data/resnet18_pytorch_project\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747173bb-89d3-45e8-b058-ab209f14610c",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0618234d-d2a4-459a-aed0-20e3803a4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a585290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6186-c5e3-4594-b469-fc776d407fe5",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Part 1</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410287ff-6594-4af8-8acc-495106d31545",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1462f12b-da03-4175-ad74-043e46166410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Part 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5263c76f-483d-42bf-9716-c526278d3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a965344-294c-4f35-881b-6f3b7e938149",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial run time: 3956.82279\n"
     ]
    }
   ],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "correct=0\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "\n",
    "# Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "        model.train() \n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z = model(x)\n",
    "        # calculate loss \n",
    "        loss = criterion(z, y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.data)\n",
    "    correct=0\n",
    "    for x_test, y_test in validation_loader:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction \n",
    "        z = model(x_test)\n",
    "        #find max \n",
    "        _, y_hat = torch.max(z.data,1)\n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        correct += (y_hat == y_test).sum().item()\n",
    "   \n",
    "    accuracy=correct/N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "end_time = time.time()\n",
    "print('initial run time: {0:.5f}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efed63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for evaluation\n",
    "FILE = 'resnet18_pytorch_trained_model.pth'\n",
    "torch.save(model, FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35507585",
   "metadata": {},
   "source": [
    "**As we can clearly see, ResNet18 model fitting time is quite satisfying with slightly above 1 hour and still produce 99.4% accuracy with good-result loss. In the next notebook, we will go through ResNet50 & VGG16 pretrained models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Part 3:Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffb287a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 23 predicted value:tensor([0]) actual value:tensor([1])\n",
      "sample 102 predicted value:tensor([1]) actual value:tensor([0])\n",
      "sample 132 predicted value:tensor([1]) actual value:tensor([0])\n",
      "sample 183 predicted value:tensor([0]) actual value:tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# Identify the first four misclassified samples using the validation data\n",
    "# FILE = 'resnet18_pytorch_trained_model.pth'\n",
    "# model = torch.load(FILE)\n",
    "count = 0\n",
    "i = 0\n",
    "for x, y in validation_dataset:\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    model.eval()\n",
    "    z = model(x)\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "    if yhat != y:\n",
    "        i += 1\n",
    "        print(f'sample {i} predicted value:{yhat} actual value:{torch.tensor([y])}')\n",
    "        count += 1\n",
    "    if yhat == y:\n",
    "        i += 1\n",
    "        continue\n",
    "    if count >= 4:\n",
    "        break                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd73d73f",
   "metadata": {},
   "source": [
    "## This is the end of this notebook. Thank you for reading til this part. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
